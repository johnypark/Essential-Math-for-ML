{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "\n",
    "###### 6/29/2021 John Park \n",
    "Logistic regression is a fantastic place to start for classification problems. It is also great to build up on our discussion about ordinary least square regression method. More importantly, it has shockingly close connection with deep neural networks (sigmoid function, recursive generalized linear model, backward propagation, updating weights). It is essential to understand logistic regression to further advance in machine learning. \n",
    "\n",
    "Logistic regression is one of the simpliest probablistic classifiers. It has bunch of advantages, and most important one is that the outcome does not get affected by collinearity of the indepdent variables, thus robust to correlated features, and therefore is suitable for large scale data analysis (Jurafsky, 2020). Whereas naive bayes is more suitable for smaller data set and is sensitive to collinearity of the features. However it is easy to implement and train the data. \n",
    "\n",
    "In this notebook, we will cover various topics arising from derivation and implementation of logistic regression. The topics include weighted linear regression, probability distribution, conditional probability, cross entropy loss, gradient decsent, probablistic classifier.   \n",
    "\n",
    "I adapted some codes from https://philippmuens.com/logistic-regression-from-scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conditional probability \n",
    "\n",
    "$$\\hat y $$\n",
    "$$ P(y=1 | X) $$\n",
    "$$ P(y=0 | X) $$\n",
    "\n",
    "##### Maximum likelihood estimation of bernoulli distribution \n",
    "$$ L (\\hat y,y) $$\n",
    "###### Cross entropy Loss LCE derivation\n",
    "$$-log(p(y| x)$$\n",
    "\n",
    "###### Partial derivative of LCE $$ L_{CE} $$\n",
    "\n",
    "###### Equation for updating weight \n",
    "\n",
    "$$ W(n+1) = W(n) - \\eta [ \\sigma(W(n)^Tx+b-y)]X $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\vmlea\\\\Documents\\\\Work\\\\Essential-Math-for-ML\\\\Chap1-Linear-Regression'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\vmlea\\\\Documents\\\\Work\\\\Essential-Math-for-ML\\\\Chap1-Linear-Regression'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigm(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "#assert sigm(0) == 0.5 #what is assert?\n",
    "\n",
    "def grad_(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/examPF.csv')\n",
    "x=df[df.columns[0]]\n",
    "y=df[df.columns[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62245933, 0.73105858, 0.81757448, 0.88079708, 0.92414182,\n",
       "       0.95257413, 0.97068777, 0.98201379, 0.98901306, 0.99330715,\n",
       "       0.99592986, 0.99752738])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sigm(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.648721\n",
       "1       2.718282\n",
       "2       4.481689\n",
       "3       7.389056\n",
       "4      12.182494\n",
       "5      20.085537\n",
       "6      33.115452\n",
       "7      54.598150\n",
       "8      90.017131\n",
       "9     148.413159\n",
       "10    244.691932\n",
       "11    403.428793\n",
       "Name: Hours studied, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
